{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Oil_Price as the feature ---\n",
      "\n",
      "Processing energy type: Coal\n",
      "Processing energy type: Gas\n",
      "Processing energy type: Nuclear\n",
      "Processing energy type: Hydro\n",
      "Processing energy type: Biomass\n",
      "Processing energy type: CCS\n",
      "Processing energy type: Solar\n",
      "Processing energy type: Onshore\n",
      "Processing energy type: Offshore\n",
      "\n",
      "RMSE: 0.0079\n",
      "MAE: 0.0071\n",
      "\n",
      "--- Using Coal_Price as the feature ---\n",
      "\n",
      "Processing energy type: Coal\n",
      "Processing energy type: Gas\n",
      "Processing energy type: Nuclear\n",
      "Processing energy type: Hydro\n",
      "Processing energy type: Biomass\n",
      "Processing energy type: CCS\n",
      "Processing energy type: Solar\n",
      "Processing energy type: Onshore\n",
      "Processing energy type: Offshore\n",
      "\n",
      "RMSE: 0.0083\n",
      "MAE: 0.0074\n",
      "\n",
      "--- Using Gas_Price as the feature ---\n",
      "\n",
      "Processing energy type: Coal\n",
      "Processing energy type: Gas\n",
      "Processing energy type: Nuclear\n",
      "Processing energy type: Hydro\n",
      "Processing energy type: Biomass\n",
      "Processing energy type: CCS\n",
      "Processing energy type: Solar\n",
      "Processing energy type: Onshore\n",
      "Processing energy type: Offshore\n",
      "\n",
      "RMSE: 0.0069\n",
      "MAE: 0.0061\n",
      "\n",
      "--- Final Results ---\n",
      "\n",
      "       Feature Energy Type  Predicted   Real     Error\n",
      "0    Oil_Price        Coal   0.061636  0.056  0.005636\n",
      "1    Oil_Price         Gas   0.039665  0.034  0.005665\n",
      "2    Oil_Price     Nuclear   0.058037  0.052  0.006037\n",
      "3    Oil_Price       Hydro   0.050577  0.045  0.005577\n",
      "4    Oil_Price     Biomass   0.061636  0.056  0.005636\n",
      "5    Oil_Price         CCS   0.060464  0.056  0.004464\n",
      "6    Oil_Price       Solar   0.064097  0.051  0.013097\n",
      "7    Oil_Price     Onshore   0.061816  0.048  0.013816\n",
      "8    Oil_Price    Offshore   0.066642  0.063  0.003642\n",
      "9   Coal_Price        Coal   0.061447  0.056  0.005447\n",
      "10  Coal_Price         Gas   0.039475  0.034  0.005475\n",
      "11  Coal_Price     Nuclear   0.057827  0.052  0.005827\n",
      "12  Coal_Price       Hydro   0.050379  0.045  0.005379\n",
      "13  Coal_Price     Biomass   0.061447  0.056  0.005447\n",
      "14  Coal_Price         CCS   0.061130  0.056  0.005130\n",
      "15  Coal_Price       Solar   0.056572  0.051  0.005572\n",
      "16  Coal_Price     Onshore   0.061515  0.048  0.013515\n",
      "17  Coal_Price    Offshore   0.048153  0.063  0.014847\n",
      "18   Gas_Price        Coal   0.060301  0.056  0.004301\n",
      "19   Gas_Price         Gas   0.038328  0.034  0.004328\n",
      "20   Gas_Price     Nuclear   0.056655  0.052  0.004655\n",
      "21   Gas_Price       Hydro   0.049235  0.045  0.004235\n",
      "22   Gas_Price     Biomass   0.060301  0.056  0.004301\n",
      "23   Gas_Price         CCS   0.058512  0.056  0.002512\n",
      "24   Gas_Price       Solar   0.063171  0.051  0.012171\n",
      "25   Gas_Price     Onshore   0.059620  0.048  0.011620\n",
      "26   Gas_Price    Offshore   0.056191  0.063  0.006809\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, randint\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Transition_WACC_And_Price.xlsx'  # Replace with the path to your file\n",
    "data = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "\n",
    "# Define energy types and their real values for 2018 (in percentage form)\n",
    "energy_types = [ 'Nuclear', 'Hydro', 'Biomass', 'CCS', 'Solar', 'Onshore', 'Offshore']\n",
    "real_values_2018 = [ 5.2, 4.5, 5.6, 5.6, 5.1, 4.8, 6.3]\n",
    "\n",
    "# Convert real values to decimal format (e.g., 5.6% -> 0.056)\n",
    "real_values_2018 = [value / 100 for value in real_values_2018]\n",
    "\n",
    "# Define features for energy prices\n",
    "features = {\n",
    "    'Oil_Price': data[['Oil_Price']],\n",
    "    'Coal_Price': data[['Coal_Price']],\n",
    "    'Gas_Price': data[['Gas_Price']]\n",
    "}\n",
    "\n",
    "# Normalize the feature data\n",
    "scaler = StandardScaler()\n",
    "for key in features:\n",
    "    features[key] = pd.DataFrame(scaler.fit_transform(features[key]), columns=features[key].columns)\n",
    "\n",
    "# Define base learners for the stacking regressor\n",
    "base_learners = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=300, max_depth=15, random_state=42)),  # Random forest with increased trees and depth\n",
    "    ('xgb', xgb.XGBRegressor(n_estimators=300, max_depth=12, learning_rate=0.03, random_state=42))  # XGBoost with fine-tuned parameters\n",
    "]\n",
    "\n",
    "# Initialize the stacking regressor\n",
    "stack_regressor = StackingRegressor(estimators=base_learners, final_estimator=LinearRegression())\n",
    "\n",
    "# Define hyperparameter search space for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'rf__n_estimators': randint(200, 400),          # Random forest: number of trees\n",
    "    'rf__max_depth': randint(10, 20),               # Random forest: depth of trees\n",
    "    'xgb__n_estimators': randint(200, 400),         # XGBoost: number of trees\n",
    "    'xgb__learning_rate': uniform(0.01, 0.05),      # XGBoost: learning rate\n",
    "    'xgb__max_depth': randint(10, 15)               # XGBoost: depth of trees\n",
    "}\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each type of price feature\n",
    "for feature_name, feature_data in features.items():\n",
    "    print(f\"\\n--- Using {feature_name} as the feature ---\\n\")\n",
    "    predicted_values_2018 = []\n",
    "\n",
    "    # Predict WACC for each energy type\n",
    "    for energy_index, energy in enumerate(energy_types):\n",
    "        print(f\"Processing energy type: {energy}\")\n",
    "        y = data[energy]  # Target variable\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feature_data, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Check if there is enough data to train and test\n",
    "        if len(X_train) < 2 or len(y_train) < 2:\n",
    "            print(f\"Skipping {energy} due to insufficient data.\")\n",
    "            continue\n",
    "\n",
    "        # Use RandomizedSearchCV for hyperparameter tuning\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=stack_regressor,\n",
    "            param_distributions=param_distributions,\n",
    "            n_iter=50,        # Increase random search iterations\n",
    "            cv=5,             # Use 5-fold cross-validation for robustness\n",
    "            scoring='neg_mean_absolute_error',  # Optimize for MAE\n",
    "            n_jobs=-1,        # Use all available CPU cores\n",
    "            random_state=42\n",
    "        )\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        # Use the best model to predict the WACC for 2018\n",
    "        if feature_name == 'Oil_Price':\n",
    "            price_2018 = pd.DataFrame([[68.34]], columns=['Oil_Price'])  # Wrap the value in a DataFrame with the correct column name\n",
    "        elif feature_name == 'Coal_Price':\n",
    "            price_2018 = pd.DataFrame([[102.36]], columns=['Coal_Price'])  # Wrap the value in a DataFrame with the correct column name\n",
    "        elif feature_name == 'Gas_Price':\n",
    "            price_2018 = pd.DataFrame([[7.17]], columns=['Gas_Price'])  # Wrap the value in a DataFrame with the correct column name\n",
    "\n",
    "        predicted_value = random_search.best_estimator_.predict(price_2018)[0]\n",
    "        predicted_values_2018.append(predicted_value)\n",
    "\n",
    "    # Ensure that the number of predicted and real values matches\n",
    "    if len(predicted_values_2018) == len(real_values_2018):\n",
    "        # Store the predicted and real values in the results\n",
    "        for energy_index, (predicted, real) in enumerate(zip(predicted_values_2018, real_values_2018)):\n",
    "            results.append({\n",
    "                'Feature': feature_name,\n",
    "                'Energy Type': energy_types[energy_index],\n",
    "                'Predicted': predicted,\n",
    "                'Real': real,\n",
    "                'Error': abs(predicted - real)  # Calculate absolute error for each prediction\n",
    "            })\n",
    "\n",
    "        # Calculate RMSE and MAE\n",
    "        rmse = np.sqrt(mean_squared_error(real_values_2018, predicted_values_2018))\n",
    "        mae = mean_absolute_error(real_values_2018, predicted_values_2018)\n",
    "\n",
    "        # Print RMSE and MAE\n",
    "        print(f\"\\nRMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "    else:\n",
    "        print(f\"Skipping final evaluation for {feature_name} due to mismatched data sizes.\")\n",
    "\n",
    "# Convert results to a DataFrame for easier visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n--- Final Results ---\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Optionally save the results to a file\n",
    "results_df.to_excel('Predicted_vs_Real_Results_Improved.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
